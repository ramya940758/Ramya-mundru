{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ramya940758/Ramya-mundru/blob/main/mundru_ramya_excercise_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fW5_oFVd9-pY"
      },
      "source": [
        "## The second In-class-exercise (09/13/2023, 40 points in total)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kindly use the provided .ipynb document to write your code or respond to the questions. Avoid generating a new file.\n",
        "Execute all the cells before your final submission."
      ],
      "metadata": {
        "id": "mAzh1U0sE5I5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This in-class exercise is due tomorrow September 14, 2023 at 11:59 PM. No late submissions will be considered."
      ],
      "metadata": {
        "id": "PpgvZQdRE-HV"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QBZI-je9-pZ"
      },
      "source": [
        "The purpose of this exercise is to understand users' information needs, then collect data from different sources for analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWoKpYQT9-pa"
      },
      "source": [
        "Question 1 (10 points): Describe an interesting research question (or practical question or something innovative) you have in mind, what kind of data should be collected to answer the question(s)? How many data needed for the analysis? The detail steps for collecting and save the data."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The research question i would like to research is number of fatalities that ahs been caused due to the aircraft each year. We would like to caluclate trend in the death casualities from navy, arny and airforrce. In order to caluclate the trend we need the number of people on board for the flight and number of people who died when an accident has been happened and people died on air as well as people died after taking them to the hospiotal. We need the data for atlease two decaded in order to get the trend . We should search kaggle in order to get the relevant data set we should get the required data by matching our attributes to the kaggle data set. We should get the data from kaggle and we should upload in into our system and save the data frame with the data"
      ],
      "metadata": {
        "id": "h77T00V3CU3y"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MlxTLRNm9-pa"
      },
      "source": [
        "Question 2 (10 points): Write python code to collect 1000 data samples you discussed above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "QpWOgjHi9-pa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "870a8b9d-f1a3-462a-dc3c-a67c7361f256"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Year Quarter      Month  Day Country/Region Aircraft Manufacturer  \\\n",
            "0     1908   Qtr 3  September   17       Virginia          Wright Flyer   \n",
            "1     1909   Qtr 3  September    7        France?                Wright   \n",
            "2     1912   Qtr 3       July   12            New            Dirigible?   \n",
            "3     1913   Qtr 3     August    6        British               Curtiss   \n",
            "4     1913   Qtr 3  September    9            NaN              Zeppelin   \n",
            "...    ...     ...        ...  ...            ...                   ...   \n",
            "5025  2022   Qtr 4   November    6       Tanzania                   ATR   \n",
            "5026  2022   Qtr 4   November   18           Peru                Airbus   \n",
            "5027  2022   Qtr 4   November   21       Colombia                 Piper   \n",
            "5028  2023   Qtr 1    January   15          Nepal                   ATR   \n",
            "5029  2023   Qtr 3  September   16         Brazil               Embraer   \n",
            "\n",
            "                             Aircraft  \\\n",
            "0                   Wright Flyer III?   \n",
            "1                   Wright ByplaneSC1   \n",
            "2                          Dirigible?   \n",
            "3                   Curtiss seaplane?   \n",
            "4             Zeppelin L 1 (airship)?   \n",
            "...                               ...   \n",
            "5025                     ATR 42 5005H   \n",
            "5026                Airbus 320 271NCC   \n",
            "5027                      Piper PA 31   \n",
            "5028                       ATR 72 500   \n",
            "5029  Embraer EMB 110P1 BandeirantePT   \n",
            "\n",
            "                                      Location  \\\n",
            "0                           Fort Myer Virginia   \n",
            "1                      Juvisy-sur-Orge France?   \n",
            "2                            Atlantic City New   \n",
            "3                             Victoria British   \n",
            "4     Over the North SeaMilitary - German Navy   \n",
            "...                                        ...   \n",
            "5025                           Bukoba Tanzania   \n",
            "5026                                 Lima Peru   \n",
            "5027                         MedellÃ­n Colombia   \n",
            "5028                             Pokhara Nepal   \n",
            "5029                           Barcelos Brazil   \n",
            "\n",
            "                              Operator  Sum of Ground  \\\n",
            "0                 Army U.S. - Military              0   \n",
            "1                                  NaN              0   \n",
            "2           Navy U.S. - JerseyMilitary              0   \n",
            "3     Canada          Columbia Private              0   \n",
            "4                                  NaN              0   \n",
            "...                                ...            ...   \n",
            "5025                     Air Precision              0   \n",
            "5026                             LATAM              2   \n",
            "5027                          SAS Aero              0   \n",
            "5028                     Airlines Yeti              0   \n",
            "5029                   Aerotaxi Manaus              0   \n",
            "\n",
            "      Sum of Fatalities (air)  Sum of Aboard  \n",
            "0                           1              2  \n",
            "1                           1              1  \n",
            "2                           5              5  \n",
            "3                           1              1  \n",
            "4                          14             20  \n",
            "...                       ...            ...  \n",
            "5025                       19             43  \n",
            "5026                        0            108  \n",
            "5027                        8              8  \n",
            "5028                       72             72  \n",
            "5029                       14             14  \n",
            "\n",
            "[5030 rows x 12 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df=pd.read_csv(r\"aircrashes.csv\")\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "px6wgvog9-pa"
      },
      "source": [
        "Question 3 (10 points): Write python code to collect 1000 articles from Google Scholar (https://scholar.google.com/), Microsoft Academic (https://academic.microsoft.com/home), or CiteSeerX (https://citeseerx.ist.psu.edu/index), or Semantic Scholar (https://www.semanticscholar.org/), or ACM Digital Libraries (https://dl.acm.org/) with the keyword \"information retrieval\". The articles should be published in the last 10 years (2013-2023).\n",
        "\n",
        "The following information of the article needs to be collected:\n",
        "\n",
        "(1) Title\n",
        "\n",
        "(2) Venue/journal/conference being published\n",
        "\n",
        "(3) Year\n",
        "\n",
        "(4) Authors\n",
        "\n",
        "(5) Abstract"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "P5rjlclf9-pb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebdfabd4-e670-4b92-fe48-a2eafbb87bfc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scholarly in /usr/local/lib/python3.10/dist-packages (1.7.11)\n",
            "Requirement already satisfied: arrow in /usr/local/lib/python3.10/dist-packages (from scholarly) (1.2.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from scholarly) (4.11.2)\n",
            "Requirement already satisfied: bibtexparser in /usr/local/lib/python3.10/dist-packages (from scholarly) (1.4.0)\n",
            "Requirement already satisfied: deprecated in /usr/local/lib/python3.10/dist-packages (from scholarly) (1.2.14)\n",
            "Requirement already satisfied: fake-useragent in /usr/local/lib/python3.10/dist-packages (from scholarly) (1.2.1)\n",
            "Requirement already satisfied: free-proxy in /usr/local/lib/python3.10/dist-packages (from scholarly) (1.1.1)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from scholarly) (0.25.0)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (from scholarly) (1.0.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from scholarly) (2.31.0)\n",
            "Requirement already satisfied: selenium in /usr/local/lib/python3.10/dist-packages (from scholarly) (4.12.0)\n",
            "Requirement already satisfied: sphinx-rtd-theme in /usr/local/lib/python3.10/dist-packages (from scholarly) (1.3.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from scholarly) (4.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from arrow->scholarly) (2.8.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->scholarly) (2.5)\n",
            "Requirement already satisfied: pyparsing>=2.0.3 in /usr/local/lib/python3.10/dist-packages (from bibtexparser->scholarly) (3.1.1)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated->scholarly) (1.15.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from free-proxy->scholarly) (4.9.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->scholarly) (2023.7.22)\n",
            "Requirement already satisfied: httpcore<0.19.0,>=0.18.0 in /usr/local/lib/python3.10/dist-packages (from httpx->scholarly) (0.18.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->scholarly) (3.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->scholarly) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->scholarly) (3.2.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->scholarly) (2.0.4)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->scholarly) (1.7.1)\n",
            "Requirement already satisfied: trio~=0.17 in /usr/local/lib/python3.10/dist-packages (from selenium->scholarly) (0.22.2)\n",
            "Requirement already satisfied: trio-websocket~=0.9 in /usr/local/lib/python3.10/dist-packages (from selenium->scholarly) (0.10.4)\n",
            "Requirement already satisfied: sphinx<8,>=1.6 in /usr/local/lib/python3.10/dist-packages (from sphinx-rtd-theme->scholarly) (5.0.2)\n",
            "Requirement already satisfied: docutils<0.19 in /usr/local/lib/python3.10/dist-packages (from sphinx-rtd-theme->scholarly) (0.18.1)\n",
            "Requirement already satisfied: sphinxcontrib-jquery<5,>=4 in /usr/local/lib/python3.10/dist-packages (from sphinx-rtd-theme->scholarly) (4.1)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from httpcore<0.19.0,>=0.18.0->httpx->scholarly) (3.7.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore<0.19.0,>=0.18.0->httpx->scholarly) (0.14.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7.0->arrow->scholarly) (1.16.0)\n",
            "Requirement already satisfied: sphinxcontrib-applehelp in /usr/local/lib/python3.10/dist-packages (from sphinx<8,>=1.6->sphinx-rtd-theme->scholarly) (1.0.7)\n",
            "Requirement already satisfied: sphinxcontrib-devhelp in /usr/local/lib/python3.10/dist-packages (from sphinx<8,>=1.6->sphinx-rtd-theme->scholarly) (1.0.5)\n",
            "Requirement already satisfied: sphinxcontrib-jsmath in /usr/local/lib/python3.10/dist-packages (from sphinx<8,>=1.6->sphinx-rtd-theme->scholarly) (1.0.1)\n",
            "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from sphinx<8,>=1.6->sphinx-rtd-theme->scholarly) (2.0.4)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from sphinx<8,>=1.6->sphinx-rtd-theme->scholarly) (1.1.9)\n",
            "Requirement already satisfied: sphinxcontrib-qthelp in /usr/local/lib/python3.10/dist-packages (from sphinx<8,>=1.6->sphinx-rtd-theme->scholarly) (1.0.6)\n",
            "Requirement already satisfied: Jinja2>=2.3 in /usr/local/lib/python3.10/dist-packages (from sphinx<8,>=1.6->sphinx-rtd-theme->scholarly) (3.1.2)\n",
            "Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.10/dist-packages (from sphinx<8,>=1.6->sphinx-rtd-theme->scholarly) (2.16.1)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.10/dist-packages (from sphinx<8,>=1.6->sphinx-rtd-theme->scholarly) (2.2.0)\n",
            "Requirement already satisfied: babel>=1.3 in /usr/local/lib/python3.10/dist-packages (from sphinx<8,>=1.6->sphinx-rtd-theme->scholarly) (2.12.1)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.10/dist-packages (from sphinx<8,>=1.6->sphinx-rtd-theme->scholarly) (0.7.13)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.10/dist-packages (from sphinx<8,>=1.6->sphinx-rtd-theme->scholarly) (1.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from sphinx<8,>=1.6->sphinx-rtd-theme->scholarly) (23.1)\n",
            "Requirement already satisfied: attrs>=20.1.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium->scholarly) (23.1.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium->scholarly) (2.4.0)\n",
            "Requirement already satisfied: outcome in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium->scholarly) (1.2.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium->scholarly) (1.1.3)\n",
            "Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.10/dist-packages (from trio-websocket~=0.9->selenium->scholarly) (1.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=2.3->sphinx<8,>=1.6->sphinx-rtd-theme->scholarly) (2.1.3)\n"
          ]
        }
      ],
      "source": [
        "pip install scholarly\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import csv\n",
        "\n",
        "# Define the URL for Google Scholar search\n",
        "base_url = 'https://scholar.google.com/scholar'\n",
        "query_params = {\n",
        "    'q': 'information retrieval',\n",
        "    'as_ylo': '2013',\n",
        "    'as_yhi': '2023',\n",
        "    'hl': 'en',\n",
        "}\n",
        "\n",
        "# Initialize a list to store articles\n",
        "articles = []\n",
        "\n",
        "# Perform multiple requests to get 1000 articles (adjust as needed)\n",
        "for _ in range(10):\n",
        "    # Send a GET request to Google Scholar\n",
        "    response = requests.get(base_url, params=query_params)\n",
        "\n",
        "    # Parse the HTML content of the page\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    # Extract article details\n",
        "    for result in soup.find_all('div', class_='gs_ri'):\n",
        "        title = result.find('h3').text\n",
        "        venue = result.find('div', class_='gs_a').text\n",
        "        year = venue.split('-')[-1].strip()  # Extract year from venue text\n",
        "        authors = result.find('div', class_='gs_a').find('a').text\n",
        "        abstract = result.find('div', class_='gs_rs').text if result.find('div', class_='gs_rs') else ''\n",
        "\n",
        "        # Append article details to the list\n",
        "        articles.append([title, venue, year, authors, abstract])\n",
        "\n",
        "    # Check if there is a \"Next\" button to go to the next page\n",
        "    next_button = soup.find('span', class_='gs_ico gs_ico_nav_next')\n",
        "    if not next_button:\n",
        "        break  # No more pages to scrape\n",
        "\n",
        "    # Update the query_params to navigate to the next page\n",
        "    query_params['start'] = len(articles)\n",
        "\n",
        "# Save the collected articles to a CSV file\n",
        "with open('articles.csv', mode='w', newline='', encoding='utf-8') as csv_file:\n",
        "    writer = csv.writer(csv_file)\n",
        "    writer.writerow(['Title', 'Venue', 'Year', 'Authors', 'Abstract'])\n",
        "    writer.writerows(articles)\n",
        "\n",
        "print(f'Collected {len(articles)} articles and saved to \"articles.csv\".')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2sU82jpmJosh",
        "outputId": "1553c217-8608-4447-a088-8f41e904ecbd"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collected 0 articles and saved to \"articles.csv\".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "\n",
        "def collect_articles(query, num_articles):\n",
        "    base_url = \"https://scholar.google.com/scholar\"\n",
        "    collected_articles = []\n",
        "\n",
        "    while len(collected_articles) < num_articles:\n",
        "        params = {\n",
        "            \"q\": query,\n",
        "            \"hl\": \"en\",\n",
        "            \"start\": len(collected_articles),\n",
        "        }\n",
        "\n",
        "        response = requests.get(base_url, params=params)\n",
        "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "\n",
        "\n",
        "        entries = soup.find_all(\"div\", class_=\"gs_ri\")\n",
        "\n",
        "        for entry in entries:\n",
        "            article_data = {}\n",
        "\n",
        "\n",
        "            title = entry.find(\"h3\", class_=\"gs_rt\")\n",
        "            article_data[\"Title\"] = title.text if title else \"N/A\"\n",
        "\n",
        "\n",
        "            venue = entry.find(\"div\", class_=\"gs_a\")\n",
        "            article_data[\"Venue\"] = venue.text if venue else \"N/A\"\n",
        "\n",
        "\n",
        "            year = entry.find(\"div\", class_=\"gs_a\").text.split(\" - \")[-1]\n",
        "            article_data[\"Year\"] = year if year else \"N/A\"\n",
        "\n",
        "\n",
        "            authors = entry.find(\"div\", class_=\"gs_a\").text.split(\" - \")[0]\n",
        "            article_data[\"Authors\"] = authors if authors else \"N/A\"\n",
        "\n",
        "\n",
        "            abstract = entry.find(\"div\", class_=\"gs_rs\")\n",
        "            article_data[\"Abstract\"] = abstract.text if abstract else \"N/A\"\n",
        "\n",
        "            collected_articles.append(article_data)\n",
        "\n",
        "    return collected_articles\n",
        "\n",
        "\n",
        "query = \"Data Science\"\n",
        "num_articles = 10\n",
        "\n",
        "\n",
        "articles = collect_articles(query, num_articles)\n",
        "\n",
        "\n",
        "for i, article in enumerate(articles, start=1):\n",
        "    print(f\"Article {i}:\")\n",
        "    print(f\"Title: {article['Title']}\")\n",
        "    print(f\"Venue/Journal: {article['Venue']}\")\n",
        "    print(f\"Year: {article['Year']}\")\n",
        "    print(f\"Authors: {article['Authors']}\")\n",
        "    print(f\"Abstract: {article['Abstract']}\")\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "id": "_u7SJ5McJo2G",
        "outputId": "a2558dd7-16ef-43d3-967c-3879210023de"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-70-234835c55bf1>\u001b[0m in \u001b[0;36m<cell line: 55>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m \u001b[0marticles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollect_articles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_articles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-70-234835c55bf1>\u001b[0m in \u001b[0;36mcollect_articles\u001b[0;34m(query, num_articles)\u001b[0m\n\u001b[1;32m     15\u001b[0m         }\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"html.parser\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \"\"\"\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"get\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    587\u001b[0m         }\n\u001b[1;32m    588\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m             resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    487\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m                 \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m             \u001b[0;31m# Make the request on the HTTPConnection object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 790\u001b[0;31m             response = self._make_request(\n\u001b[0m\u001b[1;32m    791\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    465\u001b[0m             \u001b[0;31m# Trigger any extra validation we need to do.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 467\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m   1090\u001b[0m         \u001b[0;31m# Force connect early to allow us to validate the connection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_closed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1092\u001b[0;31m             \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1093\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1094\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_verified\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    640\u001b[0m             )\n\u001b[1;32m    641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 642\u001b[0;31m         sock_and_verified = _ssl_wrap_socket_and_match_hostname(\n\u001b[0m\u001b[1;32m    643\u001b[0m             \u001b[0msock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m             \u001b[0mcert_reqs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcert_reqs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_ssl_wrap_socket_and_match_hostname\u001b[0;34m(sock, cert_reqs, ssl_version, ssl_minimum_version, ssl_maximum_version, cert_file, key_file, key_password, ca_certs, ca_cert_dir, ca_cert_data, assert_hostname, assert_fingerprint, server_hostname, ssl_context, tls_in_tls)\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0mserver_hostname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 783\u001b[0;31m     ssl_sock = ssl_wrap_socket(\n\u001b[0m\u001b[1;32m    784\u001b[0m         \u001b[0msock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m         \u001b[0mkeyfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/util/ssl_.py\u001b[0m in \u001b[0;36mssl_wrap_socket\u001b[0;34m(sock, keyfile, certfile, cert_reqs, ca_certs, server_hostname, ssl_version, ciphers, ssl_context, ca_cert_dir, key_password, ca_cert_data, tls_in_tls)\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mca_certs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mca_cert_dir\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mca_cert_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m             \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_verify_locations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mca_certs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mca_cert_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mca_cert_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mSSLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Do either of the question-4 tasks given below."
      ],
      "metadata": {
        "id": "yCQpbJnwTxAB"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GT3CNj_V9-pb"
      },
      "source": [
        "Question 4 (10 points): Write python code to collect 1000 posts from Twitter, or Facebook, or Instagram. You can either use hashtags, keywords, user_name, user_id, or other information to collect the data.\n",
        "\n",
        "The following information needs to be collected:\n",
        "\n",
        "(1) User_name\n",
        "\n",
        "(2) Posted time\n",
        "\n",
        "(3) Text"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import instaloader\n",
        "\n",
        "# Initialize Instaloader\n",
        "L = instaloader.Instaloader()\n",
        "\n",
        "# Login to Instagram (optional, if you want to access private profiles)\n",
        "L.login('ramyamundru2000@gmail.com', 'Ramyasai@123')\n",
        "\n",
        "# Replace 'target_username' with the Instagram username you want to collect posts from\n",
        "target_username = 'kyliejenner'\n",
        "\n",
        "# Create a profile object\n",
        "profile = instaloader.Profile.from_username(L.context, target_username)\n",
        "\n",
        "# Collect posts\n",
        "posts = []\n",
        "\n",
        "for post in profile.get_posts():\n",
        "    user_name = post.owner_username\n",
        "    posted_time = post.date\n",
        "    text = post.caption if post.caption else ''\n",
        "\n",
        "    # Append data to the list\n",
        "    posts.append({\n",
        "        'User_name': user_name,\n",
        "        'Posted_time': posted_time,\n",
        "        'Text': text\n",
        "    })\n",
        "\n",
        "# Print the first few collected posts\n",
        "for i, post_data in enumerate(posts[:5]):\n",
        "    print(f\"Post {i + 1}:\")\n",
        "    print(f\"User_name: {post_data['User_name']}\")\n",
        "    print(f\"Posted_time: {post_data['Posted_time']}\")\n",
        "    print(f\"Text: {post_data['Text']}\\n\")\n",
        "\n",
        "# Save the data to a file (e.g., JSON or CSV)\n",
        "import json\n",
        "\n",
        "with open('instagram_data.json', 'w', encoding='utf-8') as json_file:\n",
        "    json.dump(posts, json_file, ensure_ascii=False, indent=4)\n",
        "\n",
        "# Logout (if logged in)\n",
        "L.logout()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OcZJRHNZShfg",
        "outputId": "2f36fe64-9e02-4f80-b792-c5b315970982"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "JSON Query to accounts/login/: 429 Too Many Requests [retrying; skip with ^C]\n",
            "Number of requests within last 10/11/20/22/30/60 minutes grouped by type:\n",
            " *                            other:    1    1    1    1    1    1\n",
            "Instagram responded with HTTP error \"429 - Too Many Requests\". Please\n",
            "do not run multiple instances of Instaloader in parallel or within\n",
            "short sequence. Also, do not use any Instagram App while Instaloader\n",
            "is running.\n",
            "The request will be retried in 666 seconds, at 04:38.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}